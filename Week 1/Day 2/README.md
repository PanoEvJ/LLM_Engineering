# Unsupervised Pre-Training of a GPT-Style Model

Today we'll be working through a notebook focused on tokenization, and unsupervised pre-training of a GPT-style, decoder only model. 

We'll be using Andrej Karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT/tree/master) as our base model builder and architecture.

## Build üèóÔ∏è

We will train a GPT-style decoder-only model from scratch on Shakespeare data. You can find the notebook in this repository - or by following [this link](https://colab.research.google.com/drive/1W499zNqDRtbXD6wCzeKCGLqPM_DsDyEk?usp=sharing)

## Ship üö¢

Ship a completed notebook to us! There are a few questions found throughout the notebook that will need to be answered.

Provide a URL to your loom video walkthrough

## Share üöÄ

Share about your experience in a LinkedIn post, or in the Discord!

Submit your homework direclty [here](https://docs.google.com/forms/d/e/1FAIpQLSfPafkG04mgjkHGulYI_SumYZa602mCa8e5CguymkjqcXi6nQ/viewform?usp=sf_link)
